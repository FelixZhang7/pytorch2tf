{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert NN model with Multiple Output from PyTorch to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release.. Use node.outputs instead.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulated data\n",
    "`y1` is a continuous output, while `y2` is a binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8000, 20)\n",
      "Shape of X_train: (2000, 20)\n",
      "Shape of y1_train: (8000,)\n",
      "Shape of y1_test: (2000,)\n",
      "Shape of y2_train: (8000,)\n",
      "Shape of y2_test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Functions to generate y1 and y2 from X_train and X_test\n",
    "def generate_y1(array):\n",
    "    return 2 * np.sum(array) + np.random.randn()\n",
    "\n",
    "def generate_y2(array):\n",
    "    if np.sum(array) >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_size = 8000\n",
    "test_size = 2000\n",
    "\n",
    "input_size = 20\n",
    "hidden_sizes = [50, 50]\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train = np.random.randn(train_size, input_size).astype(np.float32)\n",
    "X_test = np.random.randn(test_size, input_size).astype(np.float32)\n",
    "y1_train = np.apply_along_axis(func1d=generate_y1, axis=1, arr=X_train)\n",
    "y1_test = np.apply_along_axis(func1d=generate_y1, axis=1, arr=X_test)\n",
    "y2_train = np.apply_along_axis(func1d=generate_y2, axis=1, arr=X_train)\n",
    "y2_test = np.apply_along_axis(func1d=generate_y2, axis=1, arr=X_test)\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_train:', X_test.shape)\n",
    "print('Shape of y1_train:', y1_train.shape)\n",
    "print('Shape of y1_test:', y1_test.shape)\n",
    "print('Shape of y2_train:', y2_train.shape)\n",
    "print('Shape of y2_test:', y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for class imbalance for y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1's in y2_train: 51.06 %\n",
      "Percentage of 0's in y2_train: 48.94 %\n",
      "\n",
      "Percentage of 1's in y2_test: 48.65 %\n",
      "Percentage of 0's in y2_test: 51.35 %\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of 1\\'s in y2_train: {:.2f} %'.format(np.sum(y2_train == 1) / len(y2_train) * 100))\n",
    "print('Percentage of 0\\'s in y2_train: {:.2f} %'.format(np.sum(y2_train == 0) / len(y2_train) * 100))\n",
    "print()\n",
    "print('Percentage of 1\\'s in y2_test: {:.2f} %'.format(np.sum(y2_test == 1) / len(y2_test) * 100))\n",
    "print('Percentage of 0\\'s in y2_test: {:.2f} %'.format(np.sum(y2_test == 0) / len(y2_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `Dataset` subclass to facilitate batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputDataset(Dataset):\n",
    "    def __init__(self, X, y1, y2):\n",
    "        self.X = X\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y1[idx], self.y2[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoaders for training and test set, for batch training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=MultiOutputDataset(X_train, y1_train, y2_train), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(dataset=MultiOutputDataset(X_test, y1_test, y2_test), batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleOutputModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(MultipleOutputModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fcs = []  # List of fully connected layers\n",
    "        in_size = input_size\n",
    "        \n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = nn.Linear(in_features=in_size, out_features=next_size)\n",
    "            in_size = next_size\n",
    "            self.__setattr__('fc{}'.format(i), fc)  # # set name for each fullly connected layer\n",
    "            self.fcs.append(fc)\n",
    "            \n",
    "        self.last_fc = nn.Linear(in_features=in_size, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            x = fc(x)\n",
    "            x = nn.ReLU()(x)\n",
    "        out1 = self.last_fc(x)\n",
    "        x2 = self.last_fc(x)\n",
    "        out2 = self.sigmoid(nn.ReLU()(x2))\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device used:', device)\n",
    "model_pytorch = MultipleOutputModel(input_size=input_size, hidden_sizes=hidden_sizes)\n",
    "model_pytorch = model_pytorch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultipleOutputModel(\n",
      "  (fc0): Linear(in_features=20, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (last_fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mean squared error loss for y1 and binary cross entropy loss for y2\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_pytorch.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Train loss is 71.719\n",
      "Epoch 2 completed. Train loss is 16.996\n",
      "Epoch 3 completed. Train loss is 2.556\n",
      "Epoch 4 completed. Train loss is 1.981\n",
      "Epoch 5 completed. Train loss is 1.791\n",
      "Epoch 6 completed. Train loss is 1.710\n",
      "Epoch 7 completed. Train loss is 1.663\n",
      "Epoch 8 completed. Train loss is 1.631\n",
      "Epoch 9 completed. Train loss is 1.599\n",
      "Epoch 10 completed. Train loss is 1.574\n",
      "Epoch 11 completed. Train loss is 1.554\n",
      "Epoch 12 completed. Train loss is 1.535\n",
      "Epoch 13 completed. Train loss is 1.515\n",
      "Epoch 14 completed. Train loss is 1.499\n",
      "Epoch 15 completed. Train loss is 1.482\n",
      "Epoch 16 completed. Train loss is 1.469\n",
      "Epoch 17 completed. Train loss is 1.460\n",
      "Epoch 18 completed. Train loss is 1.445\n",
      "Epoch 19 completed. Train loss is 1.439\n",
      "Epoch 20 completed. Train loss is 1.427\n",
      "Time taken to completed 20 epochs: 1.04 minutes\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_pytorch.train()\n",
    "    \n",
    "    train_loss_total = 0\n",
    "    \n",
    "    for data, target1, target2 in train_loader:\n",
    "        data, target1, target2 = data.to(device), target1.float().to(device), target2.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model_pytorch(data)\n",
    "        train_loss_1 = criterion1(output1.squeeze(), target1)\n",
    "#         print('target2:', target2)\n",
    "#         print('output2:', output2)\n",
    "        train_loss_2 = criterion2(output2.squeeze(), target2)\n",
    "        train_loss = torch.add(train_loss_1, train_loss_2)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_total += train_loss.item() * data.size(0)\n",
    "        \n",
    "    print('Epoch {} completed. Train loss is {:.3f}'.format(epoch + 1, train_loss_total / train_size))\n",
    "print('Time taken to completed {} epochs: {:.2f} minutes'.format(num_epochs, (time.time() - time_start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, output2 = model_pytorch(torch.tensor(X_test))\n",
    "min(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Test loss is 6.879\n",
      "Test accuracy is 0.897\n",
      "Time taken to complete evaluation: 0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "model_pytorch.eval()\n",
    "\n",
    "test_loss_total = 0\n",
    "total_num_corrects = 0\n",
    "threshold = 0.9\n",
    "time_start = time.time()\n",
    "\n",
    "for data, target1, target2 in test_loader:\n",
    "    data, target1, target2 = data.to(device), target1.float().to(device), target2.float().to(device)\n",
    "    output1, output2 = model_pytorch(data)\n",
    "    test_loss_1 = criterion1(output1.squeeze(), target1)\n",
    "    test_loss_2 = criterion2(output2.squeeze(), target2)\n",
    "    test_loss = torch.add(test_loss_1, test_loss_2)\n",
    "    test_loss.backward()\n",
    "    optimizer.step()\n",
    "    test_loss_total += test_loss.item() * data.size(0)\n",
    "    \n",
    "    pred = (output2 >= threshold).view_as(target2)  # to make pred have same shape as target\n",
    "    num_correct = torch.sum(pred == target2.byte()).item()\n",
    "    total_num_corrects += num_correct\n",
    "\n",
    "print('Evaluation completed. Test loss is {:.3f}'.format(test_loss_total / test_size))\n",
    "print('Test accuracy is {:.3f}'.format(total_num_corrects / test_size))\n",
    "print('Time taken to complete evaluation: {:.2f} minutes'.format((time.time() - time_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to ONNX Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights in PyTorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./models/'):\n",
    "    os.mkdir('./models/')\n",
    "\n",
    "torch.save(model_pytorch.state_dict(), './models/model_multi_outputs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from `.pt` file and export to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_output_1: tensor([[11.5031]], grad_fn=<AddmmBackward>)\n",
      "dummy_output_2: tensor([[1.0000]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model_pytorch = MultipleOutputModel(input_size=input_size, hidden_sizes=hidden_sizes)\n",
    "model_pytorch.load_state_dict(torch.load('./models/model_multi_outputs.pt'))\n",
    "# Single pass of dummy variable required\n",
    "dummy_input = torch.from_numpy(X_test[0].reshape(1, -1)).float().to(device)\n",
    "dummy_output_1, dummy_output_2 = model_pytorch(dummy_input)\n",
    "print('dummy_output_1:', dummy_output_1)\n",
    "print('dummy_output_2:', dummy_output_2)\n",
    "\n",
    "# Export to ONNX format\n",
    "torch.onnx.export(model_pytorch, dummy_input, './models/model_multi_outputs.onnx', input_names=['input'],\n",
    "                  output_names=['output1', 'output2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to TensorFlow Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ONNX model and convert to TensorFlow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\handlers\\backend\\gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:73: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:73: UserWarning: Unknown op ConstantLike in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:73: UserWarning: Unknown op DynamicSlice in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:73: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:70: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    }
   ],
   "source": [
    "model_onnx = onnx.load('./models/model_multi_outputs.onnx')\n",
    "\n",
    "tf_rep = prepare(model_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out tensors and placeholders in model (helpful during inference in TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc0.bias': <tf.Tensor 'Const:0' shape=(50,) dtype=float32>, 'fc0.weight': <tf.Tensor 'Const_1:0' shape=(50, 20) dtype=float32>, 'fc1.bias': <tf.Tensor 'Const_2:0' shape=(50,) dtype=float32>, 'fc1.weight': <tf.Tensor 'Const_3:0' shape=(50, 50) dtype=float32>, 'last_fc.bias': <tf.Tensor 'Const_4:0' shape=(1,) dtype=float32>, 'last_fc.weight': <tf.Tensor 'Const_5:0' shape=(1, 50) dtype=float32>, 'input': <tf.Tensor 'input:0' shape=(1, 20) dtype=float32>, '7': <tf.Tensor 'add:0' shape=(1, 50) dtype=float32>, '8': <tf.Tensor 'Relu:0' shape=(1, 50) dtype=float32>, '9': <tf.Tensor 'add_1:0' shape=(1, 50) dtype=float32>, '10': <tf.Tensor 'Relu_1:0' shape=(1, 50) dtype=float32>, 'output1': <tf.Tensor 'add_2:0' shape=(1, 1) dtype=float32>, '12': <tf.Tensor 'add_3:0' shape=(1, 1) dtype=float32>, '13': <tf.Tensor 'Relu_2:0' shape=(1, 1) dtype=float32>, 'output2': <tf.Tensor 'Sigmoid:0' shape=(1, 1) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf_rep.tensor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model as `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph('./models/model_multi_outputs.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Inference in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to load `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load graph, initialize session and do inference using the same dummy input above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output1: [[11.503143]]\n",
      "output2: [[0.99998987]]\n"
     ]
    }
   ],
   "source": [
    "tf_graph = load_pb('./models/model_multi_outputs.pb')\n",
    "sess = tf.Session(graph=tf_graph)\n",
    "\n",
    "output_1_tensor = tf_graph.get_tensor_by_name('add_2:0')\n",
    "output_2_tensor = tf_graph.get_tensor_by_name('Sigmoid:0')\n",
    "input_tensor = tf_graph.get_tensor_by_name('input:0')\n",
    "\n",
    "output1 = sess.run(output_1_tensor, feed_dict={input_tensor: dummy_input})\n",
    "output2 = sess.run(output_2_tensor, feed_dict={input_tensor: dummy_input})\n",
    "print('output1:', output1)\n",
    "print('output2:', output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

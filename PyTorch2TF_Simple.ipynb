{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert simple NN model from PyTorch to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (8000, 20)\n",
      "Shape of X_train: (2000, 20)\n",
      "Shape of y_train: (8000,)\n",
      "Shape of y_test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "train_size = 8000\n",
    "test_size = 2000\n",
    "\n",
    "input_size = 20\n",
    "hidden_sizes = [50, 50]\n",
    "output_size = 1\n",
    "num_classes = 2\n",
    "\n",
    "X_train = np.random.randn(train_size, input_size).astype(np.float32)\n",
    "X_test = np.random.randn(test_size, input_size).astype(np.float32)\n",
    "y_train = np.random.randint(num_classes, size=train_size)\n",
    "y_test = np.random.randint(num_classes, size=test_size)\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_train:', X_test.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `Dataset` subclass to facilitate batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoaders for training and test set, for batch training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=SimpleDataset(X_train, y_train), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(dataset=SimpleDataset(X_test, y_test), batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.fcs = []  # List of fully connected layers\n",
    "        in_size = input_size\n",
    "        \n",
    "        for i, next_size in enumerate(hidden_sizes):\n",
    "            fc = nn.Linear(in_features=in_size, out_features=next_size)\n",
    "            in_size = next_size\n",
    "            self.__setattr__('fc{}'.format(i), fc)  # set name for each fullly connected layer\n",
    "            self.fcs.append(fc)\n",
    "            \n",
    "        self.last_fc = nn.Linear(in_features=in_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            x = fc(x)\n",
    "            x = nn.ReLU()(x)\n",
    "        out = self.last_fc(x)\n",
    "        return nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device used:', device)\n",
    "model_pytorch = SimpleModel(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "model_pytorch = model_pytorch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (fc0): Linear(in_features=20, out_features=50, bias=True)\n",
      "  (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (last_fc): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set binary cross entropy loss since 2 classes only\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_pytorch.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:512: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Train loss is 0.695\n",
      "Epoch 2 completed. Train loss is 0.691\n",
      "Epoch 3 completed. Train loss is 0.689\n",
      "Epoch 4 completed. Train loss is 0.685\n",
      "Epoch 5 completed. Train loss is 0.679\n",
      "Epoch 6 completed. Train loss is 0.672\n",
      "Epoch 7 completed. Train loss is 0.665\n",
      "Epoch 8 completed. Train loss is 0.657\n",
      "Epoch 9 completed. Train loss is 0.650\n",
      "Epoch 10 completed. Train loss is 0.642\n",
      "Epoch 11 completed. Train loss is 0.633\n",
      "Epoch 12 completed. Train loss is 0.626\n",
      "Epoch 13 completed. Train loss is 0.616\n",
      "Epoch 14 completed. Train loss is 0.609\n",
      "Epoch 15 completed. Train loss is 0.599\n",
      "Epoch 16 completed. Train loss is 0.592\n",
      "Epoch 17 completed. Train loss is 0.584\n",
      "Epoch 18 completed. Train loss is 0.577\n",
      "Epoch 19 completed. Train loss is 0.570\n",
      "Epoch 20 completed. Train loss is 0.560\n",
      "Time taken to completed 20 epochs: 1.16 minutes\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_pytorch.train()\n",
    "    \n",
    "    train_loss_total = 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_pytorch(data)\n",
    "        train_loss = criterion(output, target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_total += train_loss.item() * data.size(0)\n",
    "        \n",
    "    print('Epoch {} completed. Train loss is {:.3f}'.format(epoch + 1, train_loss_total / train_size))\n",
    "print('Time taken to completed {} epochs: {:.2f} minutes'.format(num_epochs, (time.time() - time_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed. Test loss is 0.000\n",
      "Test accuracy is 0.487\n",
      "Time taken to complete evaluation: 0.02 minutes\n"
     ]
    }
   ],
   "source": [
    "model_pytorch.eval()\n",
    "\n",
    "test_loss_total = 0\n",
    "total_num_corrects = 0\n",
    "threshold = 0.5\n",
    "time_start = time.time()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.float().to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model_pytorch(data)\n",
    "    train_loss = criterion(output, target)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss_total += train_loss.item() * data.size(0)\n",
    "    \n",
    "    pred = (output >= threshold).view_as(target)  # to make pred have same shape as target\n",
    "    num_correct = torch.sum(pred == target.byte()).item()\n",
    "    total_num_corrects += num_correct\n",
    "\n",
    "print('Evaluation completed. Test loss is {:.3f}'.format(test_loss_total / test_size))\n",
    "print('Test accuracy is {:.3f}'.format(total_num_corrects / test_size))\n",
    "print('Time taken to complete evaluation: {:.2f} minutes'.format((time.time() - time_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to ONNX Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model weights in PyTorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./models/'):\n",
    "    os.mkdir('./models/')\n",
    "\n",
    "torch.save(model_pytorch.state_dict(), './models/model_simple.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from `.pt` file and export to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4538]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model_pytorch = SimpleModel(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "model_pytorch.load_state_dict(torch.load('./models/model_simple.pt'))\n",
    "\n",
    "# Single pass of dummy variable required\n",
    "dummy_input = torch.from_numpy(X_test[0].reshape(1, -1)).float().to(device)\n",
    "dummy_output = model_pytorch(dummy_input)\n",
    "print(dummy_output)\n",
    "\n",
    "# Export to ONNX format\n",
    "torch.onnx.export(model_pytorch, dummy_input, './models/model_simple.onnx', input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to TensorFlow Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ONNX model and convert to TensorFlow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\thefo\\appdata\\local\\continuum\\anaconda3\\envs\\onnx-env\\lib\\site-packages\\onnx_tf\\handlers\\backend\\gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "model_onnx = onnx.load('./models/model_simple.onnx')\n",
    "\n",
    "tf_rep = prepare(model_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out tensors and placeholders in model (helpful during inference in TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fc0.bias': <tf.Tensor 'Const:0' shape=(50,) dtype=float32>, 'fc0.weight': <tf.Tensor 'Const_1:0' shape=(50, 20) dtype=float32>, 'fc1.bias': <tf.Tensor 'Const_2:0' shape=(50,) dtype=float32>, 'fc1.weight': <tf.Tensor 'Const_3:0' shape=(50, 50) dtype=float32>, 'last_fc.bias': <tf.Tensor 'Const_4:0' shape=(1,) dtype=float32>, 'last_fc.weight': <tf.Tensor 'Const_5:0' shape=(1, 50) dtype=float32>, 'input': <tf.Tensor 'input:0' shape=(1, 20) dtype=float32>, '7': <tf.Tensor 'add:0' shape=(1, 50) dtype=float32>, '8': <tf.Tensor 'Relu:0' shape=(1, 50) dtype=float32>, '9': <tf.Tensor 'add_1:0' shape=(1, 50) dtype=float32>, '10': <tf.Tensor 'Relu_1:0' shape=(1, 50) dtype=float32>, '11': <tf.Tensor 'add_2:0' shape=(1, 1) dtype=float32>, 'output': <tf.Tensor 'Sigmoid:0' shape=(1, 1) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf_rep.tensor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model as `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph('./models/model_simple.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Inference in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to load `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load graph, initialize session and do inference using the same dummy input above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45375812]]\n"
     ]
    }
   ],
   "source": [
    "tf_graph = load_pb('./models/model_simple.pb')\n",
    "sess = tf.Session(graph=tf_graph)\n",
    "\n",
    "output_tensor = tf_graph.get_tensor_by_name('Sigmoid:0')\n",
    "input_tensor = tf_graph.get_tensor_by_name('input:0')\n",
    "\n",
    "output = sess.run(output_tensor, feed_dict={input_tensor: dummy_input})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
